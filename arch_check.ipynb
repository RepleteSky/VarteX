{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ueyama/workspace/ClimaX/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from src.climax.arch import ClimaX\n",
    "from src.climax.my_arch3 import ClimaX3\n",
    "from src.climax.my_arch2 import ClimaX2\n",
    "from climax.utils.metrics import (\n",
    "    lat_weighted_mse,\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_vars = [\n",
    "          \"land_sea_mask\",\n",
    "          \"orography\",\n",
    "          \"lattitude\",\n",
    "          \"2m_temperature\",\n",
    "          \"10m_u_component_of_wind\",\n",
    "          \"10m_v_component_of_wind\",\n",
    "          \"geopotential_50\",\n",
    "          \"geopotential_250\",\n",
    "          \"geopotential_500\",\n",
    "          \"geopotential_600\",\n",
    "          \"geopotential_700\",\n",
    "          \"geopotential_850\",\n",
    "          \"geopotential_925\",\n",
    "          \"u_component_of_wind_50\",\n",
    "          \"u_component_of_wind_250\",\n",
    "          \"u_component_of_wind_500\",\n",
    "          \"u_component_of_wind_600\",\n",
    "          \"u_component_of_wind_700\",\n",
    "          \"u_component_of_wind_850\",\n",
    "          \"u_component_of_wind_925\",\n",
    "          \"v_component_of_wind_50\",\n",
    "          \"v_component_of_wind_250\",\n",
    "          \"v_component_of_wind_500\",\n",
    "          \"v_component_of_wind_600\",\n",
    "          \"v_component_of_wind_700\",\n",
    "          \"v_component_of_wind_850\",\n",
    "          \"v_component_of_wind_925\",\n",
    "          \"temperature_50\",\n",
    "          \"temperature_250\",\n",
    "          \"temperature_500\",\n",
    "          \"temperature_600\",\n",
    "          \"temperature_700\",\n",
    "          \"temperature_850\",\n",
    "          \"temperature_925\",\n",
    "          \"relative_humidity_50\",\n",
    "          \"relative_humidity_250\",\n",
    "          \"relative_humidity_500\",\n",
    "          \"relative_humidity_600\",\n",
    "          \"relative_humidity_700\",\n",
    "          \"relative_humidity_850\",\n",
    "          \"relative_humidity_925\",\n",
    "          \"specific_humidity_50\",\n",
    "          \"specific_humidity_250\",\n",
    "          \"specific_humidity_500\",\n",
    "          \"specific_humidity_600\",\n",
    "          \"specific_humidity_700\",\n",
    "          \"specific_humidity_850\",\n",
    "          \"specific_humidity_925\",\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 =   {\"default_vars\": default_vars,\n",
    "            \"img_size\":[32, 64],\n",
    "            \"patch_size\":2,\n",
    "            \"embed_dim\":1024,\n",
    "            \"depth\":8,\n",
    "            \"decoder_depth\":2,\n",
    "            \"num_heads\":16,\n",
    "            \"mlp_ratio\":4.0,\n",
    "            \"drop_path\":0.1,\n",
    "            \"drop_rate\":0.1,\n",
    "            \"parallel_patch_embed\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 =   {\"default_vars\": default_vars,\n",
    "            \"img_size\":[32, 64],\n",
    "            \"patch_size\":2,\n",
    "            \"embed_dim\":1024,\n",
    "            \"depth\":8,\n",
    "            \"decoder_depth\":2,\n",
    "            \"num_heads\":16,\n",
    "            \"num_representative\":2,\n",
    "            \"mlp_ratio\":4.0,\n",
    "            \"drop_path\":0.1,\n",
    "            \"drop_rate\":0.1,\n",
    "            \"parallel_patch_embed\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config3 =   {\"default_vars\": default_vars,\n",
    "            \"img_size\":[32, 64],\n",
    "            \"patch_size\":2,\n",
    "            \"embed_dim\":1024,\n",
    "            \"depth\":8,\n",
    "            \"decoder_depth\":2,\n",
    "            \"num_heads\":16,\n",
    "            \"num_representative\":2,\n",
    "            \"mlp_ratio\":4.0,\n",
    "            \"drop_path\":0.1,\n",
    "            \"drop_rate\":0.1,\n",
    "            \"parallel_patch_embed\":True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パラメータ数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClimaX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108088512\n"
     ]
    }
   ],
   "source": [
    "climax = ClimaX(**config1).cuda()\n",
    "x = sum([param.numel() for param in climax.parameters()])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClimaX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196262080\n",
      "76554112\n",
      "33215488\n",
      "15675520\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 2, 4, 8]:\n",
    "    config2[\"num_representative\"] = i\n",
    "    my_climax2 = ClimaX2(**config2).cuda()\n",
    "    x = sum([param.numel() for param in my_climax2.parameters()])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClimaX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196276416\n",
      "59746176\n",
      "20579328\n",
      "8270976\n"
     ]
    }
   ],
   "source": [
    "for i in [1, 2, 4, 8]:\n",
    "    config3[\"num_representative\"] = i\n",
    "    my_climax3 = ClimaX3(**config3).cuda()\n",
    "    x = sum([param.numel() for param in my_climax3.parameters()])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 推論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = np.load(os.path.join(\"/home/ueyama/workspace/ClimaX/dataset/5.625deg_npz_06_18\", \"lat.npy\"))\n",
    "x = torch.randn(8, 48, 32, 64).cuda()\n",
    "y = torch.randn(8, 3, 32, 64).cuda()\n",
    "lead_times = torch.randn(1).cuda()\n",
    "variables = default_vars\n",
    "out_variables = [\"temperature_50\", \"temperature_250\", \"temperature_500\"]\n",
    "metric = None\n",
    "lat = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClimaX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "climax = ClimaX(**config1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 ms ± 383 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = torch.randn(8, 48, 32, 64).cuda()\n",
    "y = torch.randn(8, 3, 32, 64).cuda()\n",
    "_ =  climax(x, y, lead_times, variables, out_variables, metric, lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClimaX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2[\"num_representative\"] = 2\n",
    "my_climax2 = ClimaX2(**config2).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340 ms ± 94.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = torch.randn(8, 48, 32, 64).cuda()\n",
    "y = torch.randn(8, 3, 32, 64).cuda()\n",
    "_ = my_climax2(x, y, lead_times, variables, out_variables, metric, lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClimaX3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config3[\"num_representative\"] = 2\n",
    "my_climax3 = ClimaX3(**config3).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335 ms ± 93.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = torch.randn(8, 48, 32, 64).cuda()\n",
    "y = torch.randn(8, 3, 32, 64).cuda()\n",
    "_ = my_climax3(x, y, lead_times, variables, out_variables, metric, lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ClimaX3 regional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config3_region =   {\"default_vars\": default_vars,\n",
    "                    \"img_size\":[8, 16],\n",
    "                    \"patch_size\":2,\n",
    "                    \"embed_dim\":1024,\n",
    "                    \"depth\":8,\n",
    "                    \"decoder_depth\":2,\n",
    "                    \"num_heads\":16,\n",
    "                    \"num_representative\":2,\n",
    "                    \"mlp_ratio\":4.0,\n",
    "                    \"drop_path\":0.1,\n",
    "                    \"drop_rate\":0.1,\n",
    "                    \"parallel_patch_embed\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config3_region[\"num_representative\"] = 2\n",
    "my_climax3 = ClimaX3(**config3_region).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.9 ms ± 853 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = torch.randn(8, 48, 8, 16).cuda()\n",
    "y = torch.randn(8, 3, 8, 16).cuda()\n",
    "_ = my_climax3(x, y, lead_times, variables, out_variables, metric, lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### line profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = np.load(os.path.join(\"/home/ueyama/workspace/ClimaX/dataset/5.625deg_npz_06_18\", \"lat.npy\"))\n",
    "x = torch.randn(8, 48, 32, 64).cuda()\n",
    "y = torch.randn(8, 3, 32, 64).cuda()\n",
    "lead_times = torch.randn(1).cuda()\n",
    "variables = default_vars\n",
    "out_variables = [\"temperature_50\", \"temperature_250\", \"temperature_500\"]\n",
    "metric = None\n",
    "lat = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hoge(x0, y, lead_times, variables, out_variables, metric, lat):\n",
    "    # out_transformers = my_climax.forward_encoder(x, lead_times, variables=variables)  # R, B, L, D\n",
    "\n",
    "    if isinstance(variables, list):\n",
    "        variables = tuple(variables)\n",
    "    # x0 = x\n",
    "    xs = []\n",
    "    for k in range(my_climax3.num_representatives):\n",
    "        # tokenize each variable separately\n",
    "        embeds = []\n",
    "        var_ids = my_climax3.get_var_ids(variables, x0.device)\n",
    "\n",
    "        if my_climax3.parallel_patch_embed:\n",
    "            x = my_climax3.token_embeds(x0, var_ids)  # B, V, L, D\n",
    "        else:\n",
    "            for i in range(len(var_ids)):\n",
    "                id = var_ids[i]\n",
    "                embeds.append(my_climax3.token_embeds[k][id](x0[:, i : i + 1]))\n",
    "            x = torch.stack(embeds, dim=1)  # B, V, L, D\n",
    "\n",
    "        # add variable embedding\n",
    "        var_embed = my_climax3.get_var_emb(my_climax3.var_embed[k], variables)\n",
    "        x = x + var_embed.unsqueeze(2)  # B, V, L, D\n",
    "\n",
    "        # variable aggregation\n",
    "        # x = my_climax3.aggregate_variables(x, k)  # B, L, D\n",
    "        b, _, l, _ = x.shape\n",
    "        x = torch.einsum(\"bvld->blvd\", x)\n",
    "        x = x.flatten(0, 1)  # BxL, V, D\n",
    "\n",
    "        # var_query = my_climax3.var_query[k].repeat_interleave(x.shape[0], dim=0) # BxL, 1, D\n",
    "        var_query = my_climax3.var_query[k].repeat_interleave(x.shape[0], dim=0) # BxL, 1, D\n",
    "\n",
    "        x, _ = my_climax3.var_agg[k](var_query, x, x)  # BxL, D\n",
    "        x = x.squeeze()\n",
    "\n",
    "        x = x.unflatten(dim=0, sizes=(b, l))  # B, L, D\n",
    "\n",
    "        # add pos embedding\n",
    "        x = x + my_climax3.pos_embed[k]\n",
    "\n",
    "        # add lead time embedding\n",
    "        lead_time_emb = my_climax3.lead_time_embed(lead_times.unsqueeze(-1))  # B, D\n",
    "        lead_time_emb = lead_time_emb.unsqueeze(1)\n",
    "        x = x + lead_time_emb  # B, L, D\n",
    "\n",
    "        x = my_climax3.pos_drop(x)\n",
    "\n",
    "        xs.append(x.unsqueeze(0)) # R, B, L, D\n",
    "\n",
    "    xs = torch.cat(xs, dim=0) # R, B, L, D\n",
    "\n",
    "    batch_size = xs.shape[1]\n",
    "    # apply Transformer blocks\n",
    "\n",
    "    for i in range(my_climax3.depth):\n",
    "        xs = my_climax3.blocks[i](xs)\n",
    "        xs = my_climax3.norm[i](xs)\n",
    "        if i < my_climax3.depth - 1:\n",
    "            xo = my_climax3.cross_over[i]\n",
    "            xs = torch.einsum(\"rbld->blrd\", xs) # R, B, L, D\n",
    "            xs = torch.reshape(xs, (-1, *xs.shape[2:])) # (B, L), R, D\n",
    "            xs = xo(xs) # (B, L), R, D\n",
    "            xs = torch.reshape(xs, (batch_size, -1, *xs.shape[1:])) # B, L, R, D\n",
    "            xs = torch.einsum(\"blrd->rbld\", xs)\n",
    "\n",
    "    preds = []\n",
    "    for head, output in zip(my_climax3.heads, xs):\n",
    "        preds.append(head(output))\n",
    "    preds = sum(preds)/len(preds)  # B, L, V*p*p\n",
    "\n",
    "    preds = my_climax3.unpatchify(preds)\n",
    "    out_var_ids = my_climax3.get_var_ids(tuple(out_variables), preds.device)\n",
    "    preds = preds[:, out_var_ids]\n",
    "\n",
    "    if metric is None:\n",
    "        loss = None\n",
    "    else:\n",
    "        loss = [m(preds, y, out_variables, lat) for m in metric]\n",
    "\n",
    "    return loss, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 0.133942 s\n",
      "File: /tmp/ipykernel_1792597/1587645711.py\n",
      "Function: hoge at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def hoge(x0, y, lead_times, variables, out_variables, metric, lat):\n",
      "     2                                               # out_transformers = my_climax.forward_encoder(x, lead_times, variables=variables)  # R, B, L, D\n",
      "     3                                           \n",
      "     4         1       9168.0   9168.0      0.0      if isinstance(variables, list):\n",
      "     5         1       3418.0   3418.0      0.0          variables = tuple(variables)\n",
      "     6                                               # x0 = x\n",
      "     7         1       1198.0   1198.0      0.0      xs = []\n",
      "     8         3       6844.0   2281.3      0.0      for k in range(my_climax3.num_representatives):\n",
      "     9                                                   # tokenize each variable separately\n",
      "    10         2       1628.0    814.0      0.0          embeds = []\n",
      "    11         2      32037.0  16018.5      0.0          var_ids = my_climax3.get_var_ids(variables, x0.device)\n",
      "    12                                           \n",
      "    13         2       1829.0    914.5      0.0          if my_climax3.parallel_patch_embed:\n",
      "    14         2   17153049.0    9e+06     12.8              x = my_climax3.token_embeds(x0, var_ids)  # B, V, L, D\n",
      "    15                                                   else:\n",
      "    16                                                       for i in range(len(var_ids)):\n",
      "    17                                                           id = var_ids[i]\n",
      "    18                                                           embeds.append(my_climax3.token_embeds[k][id](x0[:, i : i + 1]))\n",
      "    19                                                       x = torch.stack(embeds, dim=1)  # B, V, L, D\n",
      "    20                                           \n",
      "    21                                                   # add variable embedding\n",
      "    22         2     230921.0 115460.5      0.2          var_embed = my_climax3.get_var_emb(my_climax3.var_embed[k], variables)\n",
      "    23         2     160090.0  80045.0      0.1          x = x + var_embed.unsqueeze(2)  # B, V, L, D\n",
      "    24                                           \n",
      "    25                                                   # variable aggregation\n",
      "    26                                                   # x = my_climax3.aggregate_variables(x, k)  # B, L, D\n",
      "    27         2      19171.0   9585.5      0.0          b, _, l, _ = x.shape\n",
      "    28         2     122993.0  61496.5      0.1          x = torch.einsum(\"bvld->blvd\", x)\n",
      "    29         2     136544.0  68272.0      0.1          x = x.flatten(0, 1)  # BxL, V, D\n",
      "    30                                           \n",
      "    31                                                   # var_query = my_climax3.var_query[k].repeat_interleave(x.shape[0], dim=0) # BxL, 1, D\n",
      "    32         2   97866250.0    5e+07     73.1          var_query = my_climax3.var_query[k].repeat_interleave(x.shape[0], dim=0) # BxL, 1, D\n",
      "    33                                           \n",
      "    34         2    1740934.0 870467.0      1.3          x, _ = my_climax3.var_agg[k](var_query, x, x)  # BxL, D\n",
      "    35         2      22248.0  11124.0      0.0          x = x.squeeze()\n",
      "    36                                           \n",
      "    37         2      44115.0  22057.5      0.0          x = x.unflatten(dim=0, sizes=(b, l))  # B, L, D\n",
      "    38                                           \n",
      "    39                                                   # add pos embedding\n",
      "    40         2     108713.0  54356.5      0.1          x = x + my_climax3.pos_embed[k]\n",
      "    41                                           \n",
      "    42                                                   # add lead time embedding\n",
      "    43         2     198572.0  99286.0      0.1          lead_time_emb = my_climax3.lead_time_embed(lead_times.unsqueeze(-1))  # B, D\n",
      "    44         2      12019.0   6009.5      0.0          lead_time_emb = lead_time_emb.unsqueeze(1)\n",
      "    45         2      43301.0  21650.5      0.0          x = x + lead_time_emb  # B, L, D\n",
      "    46                                           \n",
      "    47         2     138971.0  69485.5      0.1          x = my_climax3.pos_drop(x)\n",
      "    48                                           \n",
      "    49         2      15883.0   7941.5      0.0          xs.append(x.unsqueeze(0)) # R, B, L, D\n",
      "    50                                           \n",
      "    51         1      42834.0  42834.0      0.0      xs = torch.cat(xs, dim=0) # R, B, L, D\n",
      "    52                                           \n",
      "    53         1       1962.0   1962.0      0.0      batch_size = xs.shape[1]\n",
      "    54                                               # apply Transformer blocks\n",
      "    55                                           \n",
      "    56         9       6694.0    743.8      0.0      for i in range(my_climax3.depth):\n",
      "    57         8    8065529.0    1e+06      6.0          xs = my_climax3.blocks[i](xs)\n",
      "    58         8     408088.0  51011.0      0.3          xs = my_climax3.norm[i](xs)\n",
      "    59         8       6052.0    756.5      0.0          if i < my_climax3.depth - 1:\n",
      "    60         7      36227.0   5175.3      0.0              xo = my_climax3.cross_over[i]\n",
      "    61         7     154236.0  22033.7      0.1              xs = torch.einsum(\"rbld->blrd\", xs) # R, B, L, D\n",
      "    62         7      78961.0  11280.1      0.1              xs = torch.reshape(xs, (-1, *xs.shape[2:])) # (B, L), R, D\n",
      "    63         7    6224129.0 889161.3      4.6              xs = xo(xs) # (B, L), R, D\n",
      "    64         7      97576.0  13939.4      0.1              xs = torch.reshape(xs, (batch_size, -1, *xs.shape[1:])) # B, L, R, D\n",
      "    65         7     147815.0  21116.4      0.1              xs = torch.einsum(\"blrd->rbld\", xs)\n",
      "    66                                           \n",
      "    67         1        553.0    553.0      0.0      preds = []\n",
      "    68         3      27646.0   9215.3      0.0      for head, output in zip(my_climax3.heads, xs):\n",
      "    69         2     394909.0 197454.5      0.3          preds.append(head(output))\n",
      "    70         1      62881.0  62881.0      0.0      preds = sum(preds)/len(preds)  # B, L, V*p*p\n",
      "    71                                           \n",
      "    72         1      69485.0  69485.0      0.1      preds = my_climax3.unpatchify(preds)\n",
      "    73         1       5080.0   5080.0      0.0      out_var_ids = my_climax3.get_var_ids(tuple(out_variables), preds.device)\n",
      "    74         1      39986.0  39986.0      0.0      preds = preds[:, out_var_ids]\n",
      "    75                                           \n",
      "    76         1        440.0    440.0      0.0      if metric is None:\n",
      "    77         1        310.0    310.0      0.0          loss = None\n",
      "    78                                               else:\n",
      "    79                                                   loss = [m(preds, y, out_variables, lat) for m in metric]\n",
      "    80                                           \n",
      "    81         1        292.0    292.0      0.0      return loss, preds"
     ]
    }
   ],
   "source": [
    "%lprun -f hoge hoge(x, y, lead_times, variables, out_variables, metric, lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "from torch.jit import Final\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "import math\n",
    "\n",
    "class Linear3d(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, extra_dim: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.extra_dim = extra_dim\n",
    "        self.weight = Parameter(torch.empty((input_dim, output_dim, extra_dim)))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(output_dim, extra_dim))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        print(input.shape)\n",
    "        print(self.weight.shape)\n",
    "        print(self.bias.shape)\n",
    "        input = torch.einsum(\"bncr, cdr->bndr\",  (input, self.weight))\n",
    "        if self.bias is not None:\n",
    "            input = input + self.bias.view(1, *self.bias.shape)\n",
    "        return input\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f'input_dim={self.input_dim}, output_dim={self.output_dim}, bias={self.bias is not None}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = Linear3d(10,30,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 40, 10, 3])\n",
      "torch.Size([10, 30, 3])\n",
      "torch.Size([30, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 40, 30, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 40, 10, 3) # B, N, C, R\n",
    "x = linear(x)\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climaX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
